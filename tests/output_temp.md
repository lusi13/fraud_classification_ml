=== Full Machine Learning Pipeline Demo ===
This demo will:
1. Load the insurance fraud dataset
2. Preprocess the data (cleaning, encoding, normalization)
3. Split into train/test sets
4. Train Logistic Regression and Random Forest classifiers
5. Perform cross-validation on training data
6. Evaluate both models on the test set
7. Compare final results

ğŸ“ Step 1: Loading Insurance Fraud Dataset...
==================================================
Dataset loading completed:
  - Total lines processed: 15420
  - Valid records loaded: 15420
  - Records skipped: 0
âœ… Successfully loaded 15420 insurance records

ğŸ”§ Step 2: Data Preprocessing...
==================================================
Starting data preprocessing...
Cleaning data...
Fixed 320 invalid age values
Encoding features...
Checking for constant features...
No constant features found - all features have variation
Normalizing numerical features...
Age normalized: min=16,00, max=80,00, range=64,00
Preprocessing complete: 15420 samples, 59 features
âœ… Data preprocessing completed
   Features: 59
   Samples: 15420
   Class distribution:
     Legitimate claims: 14497 (94,0%)
     Fraudulent claims: 923 (6,0%)

âœ‚ï¸ Step 3: Train/Test Split...
==================================================
Split: 12336 training, 3084 test samples
âœ… Data split completed
   Training samples: 12336
   Test samples: 3084

ğŸ¤– Step 4: Training Machine Learning Models...
==================================================
Training Logistic Regression Classifier...
Logistic Regression training completed successfully.
Number of features: 59
Number of training samples: 12336
âœ… Logistic Regression trained - Training Accuracy: 93,95%
Training Random Forest Classifier...
Random Forest training completed successfully.
Number of features: 59
Number of training samples: 12336
Number of trees: 100
Variables considered per split: 7
âœ… Random Forest trained - Training Accuracy: 94,56%

ğŸ”„ Step 5: Cross-Validation Evaluation...
==================================================
Evaluating Logistic Regression with 5-fold Cross-Validation:
=== 5-Fold Cross-Validation ===
Total samples: 12336
Shuffle data: True
Random seed: 42

Fold 1/5:
    Fold 1: Removing 1 constant feature(s) from this fold
Logistic Regression training completed successfully.
Number of features: 58
Number of training samples: 9868
  Training samples: 9868
  Test samples: 2468
  Test accuracy: 93,60%

Fold 2/5:
Logistic Regression training completed successfully.
Number of features: 59
Number of training samples: 9869
  Training samples: 9869
  Test samples: 2467
  Test accuracy: 94,20%

Fold 3/5:
Logistic Regression training completed successfully.
Number of features: 59
Number of training samples: 9869
  Training samples: 9869
  Test samples: 2467
  Test accuracy: 94,08%

Fold 4/5:
Logistic Regression training completed successfully.
Number of features: 59
Number of training samples: 9869
  Training samples: 9869
  Test samples: 2467
  Test accuracy: 94,16%

Fold 5/5:
    Fold 5: Removing 1 constant feature(s) from this fold
Logistic Regression training completed successfully.
Number of features: 58
Number of training samples: 9869
  Training samples: 9869
  Test samples: 2467
  Test accuracy: 93,84%

=== Cross-Validation Summary ===
Mean Test Accuracy: 93,98% Â± 0,25%
Mean Training Accuracy: 93,96% Â± 0,06%
Best Fold: 2 (Accuracy: 94,20%)
Worst Fold: 1 (Accuracy: 93,60%)
===============================
Evaluating Random Forest with 5-fold Cross-Validation:
=== 5-Fold Cross-Validation ===
Total samples: 12336
Shuffle data: True
Random seed: 42

Fold 1/5:
    Fold 1: Removing 1 constant feature(s) from this fold
Random Forest training completed successfully.
Number of features: 58
Number of training samples: 9868
Number of trees: 100
Variables considered per split: 7
  Training samples: 9868
  Test samples: 2468
  Test accuracy: 94,04%

Fold 2/5:
Random Forest training completed successfully.
Number of features: 59
Number of training samples: 9869
Number of trees: 100
Variables considered per split: 7
  Training samples: 9869
  Test samples: 2467
  Test accuracy: 94,57%

Fold 3/5:
Random Forest training completed successfully.
Number of features: 59
Number of training samples: 9869
Number of trees: 100
Variables considered per split: 7
  Training samples: 9869
  Test samples: 2467
  Test accuracy: 94,33%

Fold 4/5:
Random Forest training completed successfully.
Number of features: 59
Number of training samples: 9869
Number of trees: 100
Variables considered per split: 7
  Training samples: 9869
  Test samples: 2467
  Test accuracy: 94,53%

Fold 5/5:
    Fold 5: Removing 1 constant feature(s) from this fold
Random Forest training completed successfully.
Number of features: 58
Number of training samples: 9869
Number of trees: 100
Variables considered per split: 7
  Training samples: 9869
  Test samples: 2467
  Test accuracy: 93,84%

=== Cross-Validation Summary ===
Mean Test Accuracy: 94,26% Â± 0,31%
Mean Training Accuracy: 94,61% Â± 0,10%
Best Fold: 2 (Accuracy: 94,57%)
Worst Fold: 5 (Accuracy: 93,84%)
===============================
ğŸ“Š Step 6: Final Test Set Evaluation...
==================================================
Logistic Regression Test Results:
  Test Accuracy: 93,71%
Random Forest Test Results:
  Test Accuracy: 94,00%

ğŸ“ˆ Step 7: Comprehensive Results Analysis...
==================================================
CROSS-VALIDATION COMPARISON:
Logistic Regression CV: 93,98% Â± 0,25%
Random Forest CV:       94,26% Â± 0,31%

TEST SET PERFORMANCE:
Logistic Regression: 93,71%
Random Forest:       94,00%

=== Logistic Regression Performance Metrics ===

ğŸ“Š CORE METRICS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Metric    â”‚  Value  â”‚           Interpretation        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Accuracy    â”‚  93,7% â”‚ Overall correctness             â”‚
â”‚ Precision   â”‚   0,0% â”‚ Fraud predictions reliability   â”‚
â”‚ Recall      â”‚   0,0% â”‚ Fraud detection completeness    â”‚
â”‚ F1-Score    â”‚   0,0% â”‚ Balanced precision/recall       â”‚
â”‚ Specificity â”‚  99,9% â”‚ Legitimate detection rate       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”¢ CONFUSION MATRIX:
                    PREDICTED
                 Legit    Fraud
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  Legitâ”‚  2890        4   â”‚
ACTUAL â”‚                         â”‚
 Fraud â”‚   190        0   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¼ BUSINESS IMPACT:
  â€¢ Total test cases: 3.084
  â€¢ Actual fraud cases: 190 (6,2%)
  â€¢ Actual legitimate cases: 2.894 (93,8%)

  â€¢ Correctly identified fraud: 0 out of 190 (0,0%)
  â€¢ Missed fraud cases: 190 (could cost money!)
  â€¢ False alarms: 4 (unnecessary investigations)
  â€¢ Correctly cleared legitimate: 2.890 out of 2.894

ğŸ¯ PROBABILITY ANALYSIS:
  â€¢ Average fraud probability for actual fraud cases: 0,131
  â€¢ Average fraud probability for legitimate cases: 0,057
  â€¢ Probability separation: 0,075

ğŸ” MODEL INTERPRETATION:
  âš ï¸  Model is too conservative - doesn't predict any fraud!
      This minimizes false alarms but misses all fraud cases.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

=== Random Forest Performance Metrics ===

ğŸ“Š CORE METRICS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Metric    â”‚  Value  â”‚           Interpretation        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Accuracy    â”‚  94,0% â”‚ Overall correctness             â”‚
â”‚ Precision   â”‚ 100,0% â”‚ Fraud predictions reliability   â”‚
â”‚ Recall      â”‚   2,6% â”‚ Fraud detection completeness    â”‚
â”‚ F1-Score    â”‚   5,1% â”‚ Balanced precision/recall       â”‚
â”‚ Specificity â”‚ 100,0% â”‚ Legitimate detection rate       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”¢ CONFUSION MATRIX:
                    PREDICTED
                 Legit    Fraud
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  Legitâ”‚  2894        0   â”‚
ACTUAL â”‚                         â”‚
 Fraud â”‚   185        5   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¼ BUSINESS IMPACT:
  â€¢ Total test cases: 3.084
  â€¢ Actual fraud cases: 190 (6,2%)
  â€¢ Actual legitimate cases: 2.894 (93,8%)

  â€¢ Correctly identified fraud: 5 out of 190 (2,6%)
  â€¢ Missed fraud cases: 185 (could cost money!)
  â€¢ False alarms: 0 (unnecessary investigations)
  â€¢ Correctly cleared legitimate: 2.894 out of 2.894

ğŸ¯ PROBABILITY ANALYSIS:
  â€¢ Average fraud probability for actual fraud cases: 0,051
  â€¢ Average fraud probability for legitimate cases: 0,009
  â€¢ Probability separation: 0,042

ğŸ” MODEL INTERPRETATION:
  ğŸ¯ Model is conservative - high precision, low recall
      When it predicts fraud, it's usually right, but misses many cases.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”„ === COMPREHENSIVE MODEL COMPARISON === ğŸ”„

ğŸ“Š TEST SET PERFORMANCE COMPARISON:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Metric      â”‚ Logistic Regresâ”‚  Random Forest  â”‚   Best Model    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Accuracy        â”‚       93,7%     â”‚       94,0%     â”‚   Random Forest â”‚
â”‚ Precision       â”‚        0,0%     â”‚      100,0%     â”‚   Random Forest â”‚
â”‚ Recall          â”‚        0,0%     â”‚        2,6%     â”‚   Random Forest â”‚
â”‚ F1-Score        â”‚        0,0%     â”‚        5,1%     â”‚   Random Forest â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”„ CROSS-VALIDATION PERFORMANCE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CV Metric     â”‚ Logistic Regresâ”‚  Random Forest  â”‚   Best Model    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Mean Accuracy   â”‚       94,0%     â”‚       94,3%     â”‚   Random Forest â”‚
â”‚ Std Deviation   â”‚        0,3%     â”‚        0,3%     â”‚    Logistic Reg â”‚
â”‚ Best Fold       â”‚       94,2%     â”‚       94,6%     â”‚   Random Forest â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ•µï¸ FRAUD DETECTION EFFECTIVENESS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Outcome      â”‚ Logistic Regresâ”‚  Random Forest  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Fraud Detected  â”‚         0       â”‚         5       â”‚
â”‚ Fraud Missed    â”‚       190       â”‚       185       â”‚
â”‚ False Alarms    â”‚         4       â”‚         0       â”‚
â”‚ Legit Cleared   â”‚     2.890       â”‚     2.894       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’° BUSINESS IMPACT ANALYSIS:
  Total fraud cases in test set: 190

  Logistic Regression:
    â€¢ Caught 0 fraud cases (0,0% detection rate)
    â€¢ Missed 190 fraud cases (potential losses)
    â€¢ Generated 4 false alarms (investigation costs)

  Random Forest:
    â€¢ Caught 5 fraud cases (2,6% detection rate)
    â€¢ Missed 185 fraud cases (potential losses)
    â€¢ Generated 0 false alarms (investigation costs)